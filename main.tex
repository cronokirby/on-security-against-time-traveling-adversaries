\include{preamble.tex}

\date{\today}
\title{On Security Against Time Traveling Adversaries}
\author{Lúcás Críostóir Meier\\\texttt{lucas@cronokirby.com}}

\begin{document}

\maketitle

\begin{abstract}
    \noindent In this work, we investigate the notion of
    time travel, formally defining a model for adversaries
    equipped with a time machine, and the subsequent consequences
    on common cryptographic schemes.
\end{abstract}

\section{Introduction}

\cite{maurer_unifying_2009}

\section{Defining Abstract Games}

In this section, we develop a framework to abstract over essentially all
security games used to define the standalone security of cryptographic schemes.

We need such an abstraction in order to explore and compare different models
of time travel.
By having an abstract game, we can more easily define what it means to augment
an adversary with the ability to travel through time, and we can more easily
compare the differences between models of time travel across \emph{all}
games, rather than for just a particular cryptographic scheme.

\subsection{State-Separable Proofs}

But first, we need a basic notion of standalone security.
For this, we lean on the framework of \emph{state-separable proofs}
\todo{cite}.

In this framework, you start with \emph{packages}.
A package $P$ is defined by its code.
This codes describes how to initialize the state of the package, 
and what functions the package exports.
These exported functions are denoted by the set $\text{out}(P)$.
Each of these functions can accept input, produce output, and read and write
to the internal state of the package.
Packages may also have a set of imported functions, denoted by $\text{in}(P)$.

These imported functions are just ``placeholders'', with no semantics.
For them to have meaning, the package needs to be \emph{linked} with another package.
If $A$ and $B$ are packages such that $\text{in}(A) \subseteq \text{out}(B)$,
then we can define the composition package $A \circ B$.
The exports are that of $A$, with $\text{out}(A \circ B) = \text{out}(A)$,
and the imports that of $B$, with $\text{in}(A \circ B) = \text{in}(B)$.
This package is implemented by merging the states of $A$ and $B$, and replacing
calls to the functions in $\text{in}(A)$ with the functionality defined in $B$.

A \emph{game} $G$ is a package with
$\text{in}(G) = \emptyset$.

An \emph{adversary} $\mathcal{A}$ is a package with $\text{out}(\mathcal{A}) = \{\texttt{guess}\}$.
The function $\texttt{guess}$ takes no input, and returns a single bit $\hat{b}$.
This bit represents the adversary's guess as to which of two games it's playing.
Furthermore, if the function $\texttt{guess}$ has a time complexity polynomial
in a security parameter $\lambda$, we say that the adversary is \emph{efficient}.
Most commonly, we assume that all adversaries are efficient, unless we explicitly
mark an adversary as \emph{unbounded}.

By linking an adversary with a game, we get a package $\mathcal{A} \circ G$
with no imports, and a single export $\texttt{guess}$.
This allows us to define the advantage of an adversary $\mathcal{A}$
in distinguishing two games $G_0, G_1$, via the formula:

$$
\epsilon(\mathcal{A} \circ G_b) := \left|P[1 \gets \texttt{guess}()\ |\ b = 0] - P[1 \gets \texttt{guess}() \ |\ b = 1]\right|
$$

Given we a pair of games $G_0, G_1$, we say that they are:

\begin{itemize}
    \item \emph{equal}, denoted by $G_0 = G_1$, when $\epsilon(\mathcal{A} \circ G_b) = 0$ for any adversary, even unbounded.
    \item \emph{indistinguishable}, denoted by $G_0 \approx G_1$, when $\epsilon(\mathcal{A} \circ G_b)$ is a negligeable function of $\lambda$, for any \emph{efficient} adversary (in $\lambda$).
\end{itemize}

The security of a cryptographic scheme is defined by a pair of games $G_b$.
We say that the scheme is \emph{secure} if $G_0 \approx G_1$.

For reductions, given game pairs $G_b$ and $H_b^1, \ldots, H_b^N$,
and a function $p$, we write:

$$
G_b \leq p(H_b^1, \ldots, H_b^n)
$$

If for any efficient adversary $\mathcal{A}$ against $G_b$, there exists efficient
adversaries $\mathcal{B}_1, \ldots, \mathcal{B}_n$ such that:

$$
\epsilon(\mathcal{A} \circ G_b) \leq p(\epsilon(\mathcal{B}_1 \circ H_b^1), \ldots, \epsilon(\mathcal{B}_n \circ H_b^n))
$$

\subsection{Abstract Games}

In the formalism of state-separable proofs, each game can have a different interface,
and maintain a different kind of state.
This is very useful, since it allows us to capture various cryptographic schemes
and notions of security.
However, in order to easily model the impacts of time travel on various games,
we would rather work with a \emph{single} interface, capable of capturing the behavior
of various games and their notions of security.

The key observation here is that the state of a pair of game is modified in only two places:

\begin{enumerate}
    \item When the state is initialized.
    \item When an exported function is called.
\end{enumerate}

We can also collapse all of the exported functions into a single function,
by including additional information in the input.
For example, the input can include which sub-function is being called,
along with the arguments to that sub-function.

The data we need to describe a game thus consist of a set of states
$\Sigma$, an initialization function $\texttt{init} : () \xrightarrow{R} \Sigma$,
as well as input and output types $X$ and $Y$, along with
a transition function ${\texttt{next} : X \times \Sigma \to Y \times \Sigma}$.

Together, these data define the following game:

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\mathcal{G}(\texttt{init}, \texttt{next})$}\cr
&s \gets \texttt{init}()\cr
&\underline{\mathcal{O}(x):}\cr
&\ s, y \gets \texttt{next}(s, x)\cr
&\ \texttt{return } y
\end{aligned}
}
$$
\caption{$\mathcal{G}(\texttt{init}, \texttt{next})$}
\end{game}

Intuitively, the game uses $\texttt{init}$ to randomly initialize the state, and
then each subsequent oracle call triggers some kind of randomized calculation
which modifies the state, and produces an output.

We can also implicitly parameterize the types and functions with a bit $b$,
allowing us to define the game pair $\mathcal{G}_b(\texttt{init}, \texttt{next})$,
which is shorthand for $\mathcal{G}(\texttt{init}_b, \texttt{next}_b)$.

This abstract game is simple, but still expressive enough to capture any
kind of game expressable in the state-separable formalism.

\section{Models of Time Travel}

In this section we investigate various models of time travel, and compare
them with each other, showing that they form a hierarchy of increasingly
strong capabilities.

The notion of time travel we explore is an intuitive one, inspired by
science fiction.
The adversary is equipped with a time machine, which allows them
to travel forwards and backwards in time.
However, the adversary must still be \emph{efficient}.
From their point of view, they only perform a number of operations
polynomial in the security parameter $\lambda$, including time travel
hops.

Some other models of time travel, like closed timelike curves, would allow,
in essence, for computation with unbounded time (but bounded space) by an adversary.
This is a much more powerful capability than we consider in this work,
and unbounded computation breaks essentially all cryptography beyond
information-theoretic schemes.

We also assume that time is \emph{discrete}.
Each interaction the adversary has with a game advances time forward
by one step, and time hops can only be made between these discrete points
in time.
One potentially stronger capability would be to allow an adversary
to ``partially'' undo the effects of an interaction, by rewinding
an interaction before its completion.
The reason we disallow this is because we assume the adversary has
no other channels to learn about the state of the game beyond the
information it gets from querying its exported functions.
An adversary thus has no way of knowing where they need to time hop
in order to partially undo an interaction, so we can make the simplifying
assumption that all interactions are \emph{atomic}, and time is discrete.

\subsection{Rewinding Models}

The first model of time travel we consider is that of \emph{rewinding},
in which the adversary is allowed to travel backwards in time.

\subsubsection{Single Rewinds}

We start by giving the adversary the ability to travel backwards
by exactly one time step.

We model this as a \emph{transformation} between games.
Given an abstract game $\mathcal{G}_b$, we define the game
$\text{Rewind-1}(\mathcal{G}_b)$ as follows:

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{Rewind-1}(\mathcal{G}_b)$}\cr
&s_0 \gets \texttt{init}_b()\cr
&i \gets 0\cr
&\begin{aligned}
    &\underline{\mathcal{O}(x):}\cr
    &s_{i + 1}, y \gets \texttt{next}_b(s_i, x)\cr
    &\texttt{return } y\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Rewind}():}\cr
    &\texttt{assert } i > 0\cr
    &i \gets i - 1\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{Rewind-1}(\mathcal{G}_b)$}
\end{game}

The interface is the same as that of $\mathcal{G}_b$, except that
we now have an additional exported function: $\texttt{Rewind}$.
Apart from this function, the behavior of the game is the same.
Each interaction with $\mathcal{O}$ advances the state.
The difference is only in the internal implementation.
Instead of a single state $s$, we now have a sequence of states
$s_0, s_1, \ldots$, as well as a position in this sequence, $i$.

The $\texttt{Rewind}$ function is the additional capability here,
and allows the adversary to move backwards by one step in time.
This essentially models a very limited time machine, only
allowing a small backwards movement in time.

Our first question is: does this limited model of time travel help
the adversary?
In other words, is an adversary with this capability more powerful
than adversary without it? 
One way of capturing this notion of power would be to demonstrate
a game $\mathcal{E}_b$ which is \emph{secure}, but where
$\text{Rewind-1}(\mathcal{E}_b)$ is broken.
In fact, we can do this:

\begin{claim}
    \label{claim:rewind-1-is-stronger}
    There exists a game $\mathcal{E}_b$ and adversary $\mathcal{A}$ such that 
    $\mathcal{E}_b$ is secure, yet $\epsilon(\mathcal{A} \circ \text{Rewind-1}(\mathcal{E}_b)) = 1$.
\end{claim}

Consider the following game:

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\mathcal{E}_b$}\cr
&k_0, k_1 \xleftarrow{R} \{0, 1\}^\lambda\cr
&\text{queried} \gets 0\cr
&\begin{aligned}
    &\underline{\texttt{Query}(\sigma):}\cr
    &\texttt{assert } \text{queried} = 0\cr
    &\text{queried} \gets 1\cr
    &\texttt{return } k_\sigma\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Guess}(\hat{k}_0, \hat{k}_1):}\cr
    &\texttt{assert } \hat{k}_0 = k_0 \land \hat{k}_1 = k_1\cr
    &\texttt{return } b\cr
    &\cr
\end{aligned}\cr
\end{aligned}
}
$$
\end{game}

In this game, we have two random keys $k_0, k_1$.
The game lets the adversary choose to learn one of the keys, but not
the other.
If the adversary manages to guess both of the keys, then they'll be
able to learn the value of $b$.

Now, because $k_\sigma$ has $\lambda$ bits, an adversary won't be able
to randomly guess its value.
This means that if the adversary only knows one of the keys, they won't
be able to pass the assertion except with negligeable probability.
This means that $\mathcal{E}_b$ is secure.

On the other hand, $\text{Rewind-1}(\mathcal{E}_b)$ is already broken.
The following strategy will always succeed:

$$
\begin{aligned}
&k_0 \gets \texttt{Query}(0)\cr
&\texttt{Rewind}()\cr
&k_1 \gets \texttt{Query}(1)\cr
&b \gets \texttt{Guess}(k_0, k_1)\cr
&\texttt{return } b\cr
\end{aligned}
$$

Even though the adversary prevents us from querying more than once,
a single rewinding step is enough to undo our query, and thus learn
the other key.

$\blacksquare$

\subsubsection{Multiple Rewinds}

Next, we consider the ability to travel backwards by multiple steps
at once.
Like before, we model this with another transformation:
$\text{Rewind-Many}$.

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{Rewind-Many}(\mathcal{G}_b)$}\cr
&s_0 \gets \texttt{init}_b()\cr
&i \gets 0\cr
&\begin{aligned}
    &\underline{\mathcal{O}(x):}\cr
    &s_{i + 1}, y \gets \texttt{next}_b(s_i, x)\cr
    &\texttt{return } y\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Rewind}(j):}\cr
    &\texttt{assert } i >= j\cr
    &i \gets i - j\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{Rewind-Many}(\mathcal{G}_b)$}
\end{game}

The only difference with $\text{Rewind-1}$ is that now the adversary
can specify a hop distance $j$, and move backwards by $j$ steps,
rather than by just a single step.

A natural question arises: is being able to jump backwards multiple
steps at a time more powerful?

No.

\begin{claim}
    \label{claim:rewind-many-is-not-strong}
    $\text{Rewind-Many}$ is as strong as $\text{Rewind-1}$.
    In particular, for any abstract game $\mathcal{G}_b$, we have
    $\text{Rewind-Many}(\mathcal{G}_b) \leq \text{Rewind-1}(\mathcal{G}_b)$.
\end{claim}

The reduction works by emulating a large jump with many tiny jumps.

We define a wrapper $\Gamma$:

$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\Gamma$}\cr
&\begin{aligned}
    &\underline{\mathcal{O}(x):}\cr
    &\texttt{return } \texttt{super}.\mathcal{O}(x)\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Rewind}(j):}\cr
    &\texttt{assert } i >= j\cr
    &\texttt{super}.\texttt{Rewind}()\ j \text{ times }\cr
\end{aligned}\cr
\end{aligned}
}
$$

It then holds that:
$$
\text{Rewind-Many}(\mathcal{G}_b) = \Gamma \circ \text{Rewind-1}(\mathcal{G}_b)
$$

The only subtlety is that we need to guarantee that this emulation
is efficient, i.e. polynomial in $\lambda$.
Because the adversary for $\mathcal{A}$ against $\text{Rewind-Many}(\mathcal{G}_b)$
is efficient, we know that they make a number of queries to $\mathcal{O}$ polynomial
in $\lambda$.
This means that the largest $i$ they reach is also bounded, and thus so will the largest
$j$ they query.
This means that the number of iterations we do in the emulation is also bounded by a polynomial
in $\lambda$, so the reduction is efficient.

$\blacksquare$

\subsection{Forking Models}

So far, we've considered a simple model of time travel in which the
adversary observes a linear sequence of states, but they're allowed to
rewind time, undoing the most recent states.

\todo{figure?}

One shortcoming of this model is that the adversary has no ability to
return to previously seen states.
For example, after reaching a state $s$, an adversary can move backwards
in time, but then loses the ability to move back to the state $s$.

While they can travel backwards in time, they can't travel \emph{forwards}
at will.

In this section, we augment the adversary with the ability to travel both
forwards and backwards and time.
To do so, we consider a model in which the adversary is allowed
to \emph{fork} the timeline, and then travel between these parallel timelines.
Instead of having a linear sequence of states, we now have a tree:

\todo{figure?}

To model this technically, we introduce the notion of \emph{savepoints}.
By creating a savepoint at particular point in time, an adversary is
able to return to the state of the game at that point in time.
Each savepoint is thus a junction point in the tree.
By returning back to a savepoint, the adversary creates a new branch
at that junction:

\todo{figure}

\subsubsection{A Stack of Savepoints}

In the first model we consider, an adversary is free to create savepoints
anywhere, but can only jump to the most recently created savepoint.
We denote this capability by $\text{Fork-Stack}$:

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{Fork-Stack}(\mathcal{G}_b)$}\cr
&\begin{aligned}
    &s \gets \texttt{init}_b()\cr
    &\text{stack} \gets \varepsilon\cr
    &\underline{\mathcal{O}(x):}\cr
    &\ s, y \gets \texttt{next}_b(s, x)\cr
    &\ \texttt{return } y\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Fork}():}\cr
    &\ \text{stack}.\text{push}(s)\cr
    &\underline{\texttt{Load}():}\cr
    &\ \texttt{assert } \neg \text{stack}.\text{empty}\cr
    &\ s \gets \text{stack}.\text{pop}()\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{Fork-Stack}(\mathcal{G}_b)$}
\end{game}

We maintain a stack of savepoints, which are just snapshots of the state
of the game, but we can only reload the most recent savepoint, consuming
it.
The adversary also needs to proactively create savepoints if they want to be able
to rewind time.

How does $\text{Fork-Stack}$ compare with $\text{Rewind-Many}$?

It turns out that they're equivalent.

\begin{claim}
    \label{claim:fork-stack-is-not-stronger}
    For all abstract games $\mathcal{G}_b$, we have both
    $\text{Fork-Stack}(\mathcal{G}_b) \leq \text{Rewind-Many}(\mathcal{G}_b)$
    and $\text{Rewind-Many}(\mathcal{G}_b) \leq \text{Fork-Stack}(\mathcal{G}_b)$.
\end{claim}

\textbf{Proof Idea:}\\
Because we can only load the most recent savepoint, we can emulate
these loads using rewinding.

In the other direction, we need to emulate rewinding with forking.
One tricky aspect is that an adversary can rewind to any point without
having to create a savepoint there in advance.
In particular, they can choose how they rewind based on the results
of interacting with the game.
To accomodate this freedom, we can simply always make a savepoint,
allowing us to rewind by loading multiples times in a row.

\textbf{Proof:}\\
First, we show that $\text{Fork-Stack}(\mathcal{G}_b) \leq \text{Rewind-Many}(\mathcal{G}_b)$.

We define a wrapper $\Gamma$:

$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\Gamma$}\cr
&\begin{aligned}
    &i \gets 0\cr
    &\text{stack} \gets \varepsilon\cr
    &\cr
    &\underline{\mathcal{O}(x):}\cr
    &\ i \gets i + 1\cr
    &\ \texttt{return } \texttt{super}.\mathcal{O}(x)\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Fork}():}\cr
    &\ \text{stack}.\text{push}(i)\cr
    &\underline{\texttt{Load}():}\cr
    &\ \texttt{assert } \neg \text{stack}.\text{empty}\cr
    &\ \hat{i} \gets \text{stack}.\text{pop}()\cr
    &\ \texttt{super}.\texttt{Rewind}(i - \hat{i})\cr
    &\ i \gets \hat{i}\cr
\end{aligned}\cr
\end{aligned}
}
$$

This wrapper satisfies:
$$
\text{Fork-Stack}(\mathcal{G}_b) = \Gamma \circ \text{Rewind-Many}(\mathcal{G}_b)
$$
Basically, instead of keeping a stack of states, we can keep a stack of indices,
and the rewinding is enough to load previous states, because we can only ever load
the most recent state on the stack.

Next, we show that $\text{Rewind-Many}(\mathcal{G}_b) \leq \text{Rewind-Many}(\mathcal{G}_b)$.

In Claim \ref{claim:rewind-many-is-not-strong}, we showed that
$\text{Rewind-Many}(\mathcal{G}_b) \leq \text{Rewind-1}(\mathcal{G}_b)$, so
it suffices to prove that $\text{Rewind-1}(\mathcal{G}_b) \leq \text{Fork-Stack}(\mathcal{G}_b)$.

We define a wrapper $\Gamma$, which works by always creating a savepoint,
and then using those to implement rewinding.

$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\Gamma$}\cr
&\begin{aligned}
    &\underline{\mathcal{O}(x):}\cr
    &\ \texttt{super}.\texttt{Fork}()\cr
    &\ \texttt{return } \texttt{super}.\mathcal{O}(x)\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Rewind}():}\cr
    &\ \texttt{super}.\texttt{Load}()\cr
    &\cr
\end{aligned}\cr
\end{aligned}
}
$$

We have:
$$
\text{Rewind-1}(\mathcal{G}_b) = \Gamma \circ \text{Fork-Stack}(\mathcal{G}_b)
$$

One subtlety is that in $\texttt{Rewind}$, we don't perform any assertions,
whereas we'd usually check that $i > 0$.
This isn't necessary because $\texttt{super}.Load$ will check that the stack
isn't empty, which performs this duty.

$\blacksquare$

\subsubsection{Arbitrary Savepoints}

In the $\text{Fork-Stack}$ model, the adversary is limited to only
load the most recently created savepoint.
As we proved in Claim \ref{claim:fork-stack-is-not-stronger}, this model
gives no advantage over just being able to move backwards in time.

In order to capture the ability to move both backwards and forwards
at will, we can remove this restriction on which savepoints can be loaded.
We now maintain a list of savepoints, and these savepoints can loaded
in any order and multiple times, at will, without any restrictions.

More formally, we capture this notion with the
$\text{Fork}$ transformation:

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{Fork}(\mathcal{G}_b)$}\cr
&\begin{aligned}
    &s_0 \gets \texttt{init}_b()\cr
    &i, j \gets 0\cr
    &\underline{\mathcal{O}(x):}\cr
    &\ s_i, y \gets \texttt{next}_b(s_i, x)\cr
    &\ \texttt{return } y\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Fork}():}\cr
    &\ j \gets j + 1\cr
    &\ s_j \gets s_i\cr
    &\underline{\texttt{Load}(i'):}\cr
    &\ \texttt{assert } i' \leq j\cr
    &\ i \gets i'\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{Fork}(\mathcal{G}_b)$}
\end{game}

The essence is that the game now maintains multiple states $s_0, s_1, \ldots$
in parallel.
At any point, the adversary is free to switch which state is currently
being used, or to create a parallel state from the current one.
This captures the intuitive notion of traveling at will between
parallel timelines.

It turns out that this model of time travel is strictly stronger than the
others we've seen so far.

\begin{claim}
    \label{claim:fork-is-strong}
    $\text{Fork}$ is strictly stronger than $\text{Fork-Stack}$,
    assuming the existence of secure pseudo-random functions.

    In particular, given a secure PRF $F$, there exists a game $\mathcal{E}_b$ and adversary $\mathcal{A}$ such that 
    $\text{Rewind-1}(\mathcal{E}_b)$ is secure, yet $\epsilon(\mathcal{A} \circ \text{Fork}(\mathcal{E}_b)) = 1$.
\end{claim}

Consider the following game:

$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\mathcal{E}_b$}\cr
&\begin{aligned}
    &k \xleftarrow{R} \mathcal{K}\cr
    &x \gets \bot\cr
    &\text{queried} \gets 0\cr
    &\cr
    &\underline{\texttt{Win}(y):}\cr
    &\ \texttt{assert } x \neq \bot\cr
    &\ \texttt{assert } F(k, x) = y\cr
    &\ \texttt{return } b\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Query}(\hat{x}):}\cr
    &\ \texttt{assert } \text{queried} = 0\cr
    &\ \text{queried} \gets 1\cr
    &\ \texttt{return } F(k, \hat{x})\cr
    &\cr
    &\underline{\texttt{Input}():}\cr
    &\ \texttt{assert } \text{queried} = 0\cr
    &\ \text{queried} \gets 1\cr
    &\ x \xleftarrow{R} \mathcal{X}\cr
    &\ \texttt{return } x\cr
\end{aligned}\cr
\end{aligned}
}
$$

The idea is that we have a pseudo-random function, seeded with
a random key $k$.
The adversary can either query the function on an input of their choice,
or attempt to win the game, by receiving a challenge input $x$,
and then responding with the evaluation of the PRF $F$ on that input.
Crucially, they're allowed to perform a query, or to prepare
the challenge input, but not both.

This game is insecure against forking, as demonstrated by the following
strategy for $\text{Fork}(\mathcal{E}_b)$:

$$
\begin{aligned}
&x \gets \texttt{Input}()\cr
&\texttt{Fork}()\cr
&\texttt{Load}(0)\cr
&y \gets \texttt{Query}(x)\cr
&\texttt{Load}(1)\cr
&b \gets \texttt{Win}(y)\cr
&\texttt{return } b
\end{aligned}
$$

On the other hand, the game $\text{Rewind-1}(\mathcal{E}_b)$ remains
secure, provided that $|\mathcal{X}|^{-1}$ is negligeable in $\lambda$.
While the adversary can use rewinding to query multiple times,
they won't know which input $x$ they need to query.
Except with negligeable probability, each new call to $\texttt{Input}$
will yield a different value of $x$.
Because the adversary cannot predict the value of $x$, nor can they
learn the output of $F$ after they know $x$, since $F$ is a secure
PRF, they cannot win the game.

$\blacksquare$

\subsection{Summary}

To summarize our findings, we have the following hierarchy of models
of time travel:
$$
\text{No-Time-Travel} < \text{Rewind-1} = \text{Rewind-Many} = \text{Fork-Stack} < \text{Fork}
$$
So, even a bit of time travel helps, but then the next jump in capability
only comes with the ability to fork timelines and travel at will between them.
In other words, being able to jump backwards helps, and being able to jump
forwards too helps even more.

\section{On Depth and Position Restrictions}

In the models we've considered so far, there are limits on what time travel capabilities
the adversary has, but not in how they can use them.
The adversary can fork whenever they want, as many times as they want,
and advance each forked timeline at will.

In this section, we model these kinds of restriction on time travel,
and compare how they relate to each other.

\subsection{Modelling Restrictions}

The first kind of restriction is on the \emph{position} where an
adversary can fork.
Without time travel, the sequence of states $s_0, s_1, \ldots$
is indexed by $\mathbb{N}$.
A natural restriction is to only allow the adversary to
fork on a subset $P \subseteq \mathbb{N}$ of these states.
For example, the adversary may only be allowed to fork on the initial
state $s_0$, but not any other states.

The second kind of restriction is on the \emph{width} of the forks.
In our current forking model, an adversary can create multiple
paths from a savepoint by loading it multiple times.
We can instead restrict the adversary to only load savepoints at most
$w$ times.

The third kind of restriction is on the \emph{depth} of the forks.
In our model, the adversary is free to explore each fork to any depth.
They can advance the state in each fork arbitrarily.
With this restriction, we instead only allow the adversary to advance
the state in a forked timeline $d$ times.

More formally, given a set of positions $P \subseteq \mathbb{N}$, and
a width and depth
$w, d \in \mathbb{N} \cup \{\infty\}$, we can define the following
transformation $\text{Fork}(P, w, d)$:

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{Fork}(P, w, d)(\mathcal{G}_b)$}\cr
&\begin{aligned}
    &s_0 \gets \texttt{init}_b()\cr
    &p_0 \gets 0\cr
    &\text{forkable} \gets \{0\}\cr
    &c_0 \gets \infty\cr
    &i, j \gets 0\cr
    &\underline{\mathcal{O}(x):}\cr
    &\ \texttt{assert } c_i > 0\cr
    &\ c_i \gets c_i - 1\cr
    &\ p_i \gets p_i + 1\cr
    &\ \text{forkable} \gets \text{forkable} \cup \{i\}\cr
    &\ s_i, y \gets \texttt{next}_b(s_i, x)\cr
    &\ \texttt{return } y\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Fork}():}\cr
    &\ \texttt{assert } p_i \in P\cr
    &\ \texttt{assert } i \in \text{forkable}\cr
    &\ j \gets j + 1\cr
    &\ s_j, p_j, l_j, c_j \gets s_i, p_i, 0, d\cr
    &\cr
    &\underline{\texttt{Load}(i'):}\cr
    &\ \texttt{assert } i' \leq j \land l_{i'} < w\cr
    &\ i \gets i'\cr
    &\ l_{i} \gets l_{i} + 1\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{Fork}(\mathcal{G}_b)$}
\end{game}

This game is like $\text{Fork}(\mathcal{G}_b)$, except with a few more restrictions.

First, we keep track of the position of each fork along the timeline,
via $p_i$. 
This allows us to prevent forks unless the position $p_i$ is contained
in the set of allowed positions $P$.

In order to restrict the depth of each fork, each fork is associated
with a counter $c_i$, which decrements each time the state advances.
The main timeline $c_0$, has the counter set to $\infty$, to allow
arbitrary progression.

Finally, to restrict the width of each fork, we keep track of the number
of times a fork has been loaded, via $l_i$.
One technicality is that we also need to prevent a state from being
forked unless it has been advanced before.
With the use of the $\text{forkable}$ set, it would be possible
to get around the width restriction by creating multiple save points
at the same spot.
By only allowing forks from a timeline after it has been advanced,
we can enforce the width restriction correctly.

\subsection{Comparing Restrictions}

$\text{Fork}(P, w, d)$ is actually equivalent to not having access
to time travel for certain parameters.
If $P = \emptyset$, $w = 0$, or $d = 0$, then forking becomes
impossible.
This means that $\text{Fork}(\emptyset, w, d) = \text{Fork}(\emptyset, w', d')$,
and similarly for the other extreme values for $w$ and $d$.

At the other extreme, $\text{Fork}(\mathbb{N}, \infty, \infty) = \text{Fork}$.
If we can fork anywhere, any number of times, and to any depth, we recover the general
model of forking defined previously.

It's clear that as $P$, $w$, and $d$ grow larger, the adversary grows
more powerful.
In particular, for all abstract games $\mathcal{G}_b$, and parameters
$P, P', w, w', d, d'$, we have:

\begin{itemize}
    \item If $P \subseteq P'$, then $\text{Fork}(P, w, d)(\mathcal{G}_b) \leq \text{Fork}(P', w, d)(\mathcal{G}_b)$.
    \item If $w \leq w'$, then $\text{Fork}(P, w, d)(\mathcal{G}_b) \leq \text{Fork}(P, w', d)(\mathcal{G}_b)$.
    \item If $d \leq d'$, then $\text{Fork}(P, w, d)(\mathcal{G}_b) \leq \text{Fork}(P, w, d')(\mathcal{G}_b)$.
\end{itemize}

But, is it possible that certain parameter values are equivalent?
If we increase the size of the parameters, is that a strictly stronger
capability?

It is.
Increasing $P$, $w$, and $d$ yields a strictly stronger adversary.

\begin{claim}
    \label{claim:P-is-stronger}
    For all $w, d > 0$, if $P' / P \neq \emptyset$, then there exists a
    game $\mathcal{E}_b$ and adversary $\mathcal{A}$ such that 
    $\text{Fork}(P, w, d)(\mathcal{E}_b)$ is secure, yet $\epsilon(\mathcal{A} \circ \text{Fork}(P', w, d)(\mathcal{E}_b)) = 1$.
\end{claim}

The basic idea of the proof is that we engineer a game which requires
the adversary to fork at a position in $P'$, but not $P$, which demonstrates
the separation.

Given $p \in P' / P$, we can construct the following game:
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\mathcal{E}_b$}\cr
&k_0, k_1 \xleftarrow{R} \{0, 1\}^\lambda\cr
&i \gets -1\cr
&\begin{aligned}
    &\underline{\texttt{Query}(\sigma):}\cr
    &\ i \gets i + 1\cr
    &\ \texttt{if } i \neq p\cr
    &\ \quad \texttt{return } \bot\cr
    &\ \texttt{return } k_\sigma\cr
\end{aligned}
&\begin{aligned}
    &\ \underline{\texttt{Guess}(\hat{k}_0, \hat{k}_1):}\cr
    &\ \texttt{assert } \hat{k}_0 = k_0 \land \hat{k}_1 = k_1\cr
    &\ \texttt{return } b\cr
    &\cr
\end{aligned}\cr
\end{aligned}
}
$$
In order to win the game, the adversary needs to learn both $k_0$
and $k_1$.
Because of their size, this requires the adversary to make two
queries, both at step $p$.
This requires the adversary to be able to fork at step $p$,
which they are unable to do in $\text{Fork}(P, w, d)(\mathcal{E}_b)$.

$\blacksquare$

\section{Effects of Time Travel on Common Schemes}

\subsection{Stateless Schemes Remain Secure}

\subsection{On Encryption}

\subsection{On Signatures}

\section{Further Work}

\section{Conclusion}

\bibliographystyle{alpha}
\small \bibliography{bib}
\end{document}
