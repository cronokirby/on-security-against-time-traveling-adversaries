\include{preamble.tex}

\date{\today}
\title{On Security Against Time Traveling Adversaries}
\author{Lúcás Críostóir Meier\\\texttt{lucas@cronokirby.com}}

\begin{document}

\maketitle

\begin{abstract}
    \noindent In this work, we investigate the notion of
    time travel, formally defining a model for adversaries
    equipped with a time machine, and the subsequent consequences
    on common cryptographic schemes.
\end{abstract}

\section{Introduction}

\section{Defining Abstract Games}

In this section, we develop a framework to abstract over essentially all
security games used to define the standalone security of cryptographic schemes.

We need such an abstraction in order to explore and compare different models
of time travel.
By having an abstract game, we can more easily define what it means to augment
an adversary with the ability to travel through time, and we can more easily
compare the differences between models of time travel across \emph{all}
games, rather than for just a particular cryptographic scheme.

\subsection{State-Separable Proofs}

But first, we need a basic notion of standalone security.
For this, we lean on the framework of \emph{state-separable proofs}
\todo{cite}.

In this framework, you start with \emph{packages}.
A package $P$ is defined by its code.
This codes describes how to initialize the state of the package, 
and what functions the package exports.
These exported functions are denoted by the set $\text{out}(P)$.
Each of these functions can accept input, produce output, and read and write
to the internal state of the package.
Packages may also have a set of imported functions, denoted by $\text{in}(P)$.

These imported functions are just ``placeholders'', with no semantics.
For them to have meaning, the package needs to be \emph{linked} with another package.
If $A$ and $B$ are packages such that $\text{in}(A) \subseteq \text{out}(B)$,
then we can define the composition package $A \circ B$.
The exports are that of $A$, with $\text{out}(A \circ B) = \text{out}(A)$,
and the imports that of $B$, with $\text{in}(A \circ B) = \text{in}(B)$.
This package is implemented by merging the states of $A$ and $B$, and replacing
calls to the functions in $\text{in}(A)$ with the functionality defined in $B$.

A \emph{game} $G$ is a package with
$\text{in}(G) = \emptyset$.

An \emph{adversary} $\mathcal{A}$ is a package with $\text{out}(\mathcal{A}) = \{\texttt{guess}\}$.
The function $\texttt{guess}$ takes no input, and returns a single bit $\hat{b}$.
This bit represents the adversary's guess as to which of two games it's playing.
Furthermore, if the function $\texttt{guess}$ has a time complexity polynomial
in a security parameter $\lambda$, we say that the adversary is \emph{efficient}.
Most commonly, we assume that all adversaries are efficient, unless we explicitly
mark an adversary as \emph{unbounded}.

By linking an adversary with a game, we get a package $\mathcal{A} \circ G$
with no imports, and a single export $\texttt{guess}$.
This allows us to define the advantage of an adversary $\mathcal{A}$
in distinguishing two games $G_0, G_1$, via the formula:

$$
\epsilon(\mathcal{A} \circ G_b) := \left|P[1 \gets \texttt{guess}()\ |\ b = 0] - P[1 \gets \texttt{guess}() \ |\ b = 1]\right|
$$

Given we a pair of games $G_0, G_1$, we say that they are:

\begin{itemize}
    \item \emph{equal}, denoted by $G_0 = G_1$, when $\epsilon(\mathcal{A} \circ G_b) = 0$ for any adversary, even unbounded.
    \item \emph{indistinguishable}, denoted by $G_0 \approx G_1$, when $\epsilon(\mathcal{A} \circ G_b)$ is a negligeable function of $\lambda$, for any \emph{efficient} adversary (in $\lambda$).
\end{itemize}

The security of a cryptographic scheme is defined by a pair of games $G_b$.
We say that the scheme is \emph{secure} if $G_0 \approx G_1$.

For reductions, given game pairs $G_b$ and $H_b^1, \ldots, H_b^N$,
and a function $p$, we write:

$$
G_b \leq p(H_b^1, \ldots, H_b^n)
$$

If for any efficient adversary $\mathcal{A}$ against $G_b$, there exists efficient
adversaries $\mathcal{B}_1, \ldots, \mathcal{B}_n$ such that:

$$
\epsilon(\mathcal{A} \circ G_b) \leq p(\epsilon(\mathcal{B}_1 \circ H_b^1), \ldots, \epsilon(\mathcal{B}_n \circ H_b^n))
$$

\subsection{Abstract Games}

In the formalism of state-separable proofs, each game can have a different interface,
and maintain a different kind of state.
This is very useful, since it allows us to capture various cryptographic schemes
and notions of security.
However, in order to easily model the impacts of time travel on various games,
we would rather work with a \emph{single} interface, capable of capturing the behavior
of various games and their notions of security.

The key observation here is that the state of a pair of game is modified in only two places:

\begin{enumerate}
    \item When the state is initialized.
    \item When an exported function is called.
\end{enumerate}

We can also collapse all of the exported functions into a single function,
by including additional information in the input.
For example, the input can include which sub-function is being called,
along with the arguments to that sub-function.

The data we need to describe a game thus consist of a set of states
$\Sigma$, an initialization function $\texttt{init} : () \xrightarrow{R} \Sigma$,
as well as input and output types $X$ and $Y$, along with
a transition function ${\texttt{next} : X \times \Sigma \to Y \times \Sigma}$.

Together, these data define the following game:

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\mathcal{G}(\texttt{init}, \texttt{next})$}\cr
&s \gets \texttt{init}()\cr
&\underline{\mathcal{O}(x):}\cr
&\ s, y \gets \texttt{next}(s, x)\cr
&\ \texttt{return } y
\end{aligned}
}
$$
\caption{$\mathcal{G}(\texttt{init}, \texttt{next})$}
\end{game}

Intuitively, the game uses $\texttt{init}$ to randomly initialize the state, and
then each subsequent oracle call triggers some kind of randomized calculation
which modifies the state, and produces an output.

We can also implicitly parameterize the types and functions with a bit $b$,
allowing us to define the game pair $\mathcal{G}_b(\texttt{init}, \texttt{next})$,
which is shorthand for $\mathcal{G}(\texttt{init}_b, \texttt{next}_b)$.

This abstract game is simple, but still expressive enough to capture any
kind of game expressable in the state-separable formalism.

\section{Models of Time Travel}

In this section we investigate various models of time travel, and compare
them with each other, showing that they form a hierarchy of increasingly
strong capabilities.

The notion of time travel we explore is an intuitive one, inspired by
science fiction.
The adversary is equipped with a time machine, which allows them
to travel forwards and backwards in time.
However, the adversary must still be \emph{efficient}.
From their point of view, they only perform a number of operations
polynomial in the security parameter $\lambda$, including time travel
hops.

Some other models of time travel, like closed timelike curves, would allow,
in essence, for computation with unbounded time (but bounded space) by an adversary.
This is a much more powerful capability than we consider in this work,
and unbounded computation breaks essentially all cryptography beyond
information-theoretic schemes.

We also assume that time is \emph{discrete}.
Each interaction the adversary has with a game advances time forward
by one step, and time hops can only be made between these discrete points
in time.
One potentially stronger capability would be to allow an adversary
to ``partially'' undo the effects of an interaction, by rewinding
an interaction before its completion.
The reason we disallow this is because we assume the adversary has
no other channels to learn about the state of the game beyond the
information it gets from querying its exported functions.
An adversary thus has no way of knowing where they need to time hop
in order to partially undo an interaction, so we can make the simplifying
assumption that all interactions are \emph{atomic}, and time is discrete.

\subsection{Rewinding Models}

The first model of time travel we consider is that of \emph{rewinding},
in which the adversary is allowed to travel backwards in time.

\subsubsection{Single Rewinds}

We start by giving the adversary the ability to travel backwards
by exactly one time step.

We model this as a \emph{transformation} between games.
Given an abstract game $\mathcal{G}_b$, we define the game
$\text{Rewind-1}(\mathcal{G}_b)$ as follows:

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{Rewind-1}(\mathcal{G}_b)$}\cr
&s_0 \gets \texttt{init}_b()\cr
&i \gets 0\cr
&\begin{aligned}
    &\underline{\mathcal{O}(x):}\cr
    &s_{i + 1}, y \gets \texttt{next}_b(s_i, x)\cr
    &\texttt{return } y\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Rewind}():}\cr
    &\texttt{assert } i > 0\cr
    &i \gets i - 1\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{Rewind-1}(\mathcal{G}_b)$}
\end{game}

The interface is the same as that of $\mathcal{G}_b$, except that
we now have an additional exported function: $\texttt{Rewind}$.
Apart from this function, the behavior of the game is the same.
Each interaction with $\mathcal{O}$ advances the state.
The difference is only in the internal implementation.
Instead of a single state $s$, we now have a sequence of states
$s_0, s_1, \ldots$, as well as a position in this sequence, $i$.

The $\texttt{Rewind}$ function is the additional capability here,
and allows the adversary to move backwards by one step in time.
This essentially models a very limited time machine, only
allowing a small backwards movement in time.

Our first question is: does this limited model of time travel help
the adversary?
In other words, is an adversary with this capability more powerful
than adversary without it? 
One way of capturing this notion of power would be to demonstrate
a game $\mathcal{E}_b$ which is \emph{secure}, but where
$\text{Rewind-1}(\mathcal{E}_b)$ is broken.
In fact, we can do this:

\begin{claim}
    \label{claim:rewind-1-is-stronger}
    There exists a game $\mathcal{E}_b$ and adversary $\mathcal{A}$ such that 
    $\mathcal{E}_b$ is secure, yet $\epsilon(\mathcal{A} \circ \text{Rewind-1}(\mathcal{E}_b)) = 1$.
\end{claim}

Consider the following game:

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\mathcal{E}_b$}\cr
&k_0, k_1 \xleftarrow{R} \{0, 1\}^\lambda\cr
&\text{queried} \gets 0\cr
&\begin{aligned}
    &\underline{\texttt{Query}(\sigma):}\cr
    &\texttt{assert } \text{queried} = 0\cr
    &\text{queried} \gets 1\cr
    &\texttt{return } k_\sigma\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Guess}(\hat{k}_0, \hat{k}_1):}\cr
    &\texttt{assert } \hat{k}_0 = k_0 \land \hat{k}_1 = k_1\cr
    &\texttt{return } b\cr
    &\cr
\end{aligned}\cr
\end{aligned}
}
$$
\end{game}

In this game, we have two random keys $k_0, k_1$.
The game lets the adversary choose to learn one of the keys, but not
the other.
If the adversary manages to guess both of the keys, then they'll be
able to learn the value of $b$.

Now, because $k_\sigma$ has $\lambda$ bits, an adversary won't be able
to randomly guess its value.
This means that if the adversary only knows one of the keys, they won't
be able to pass the assertion except with negligeable probability.
This means that $\mathcal{E}_b$ is secure.

On the other hand, $\text{Rewind-1}(\mathcal{E}_b)$ is already broken.
The following strategy will always succeed:

$$
\begin{aligned}
&k_0 \gets \texttt{Query}(0)\cr
&\texttt{Rewind}()\cr
&k_1 \gets \texttt{Query}(1)\cr
&b \gets \texttt{Guess}(k_0, k_1)\cr
&\texttt{return } b\cr
\end{aligned}
$$

Even though the adversary prevents us from querying more than once,
a single rewinding step is enough to undo our query, and thus learn
the other key.

$\blacksquare$

\subsubsection{Multiple Rewinds}

Next, we consider the ability to travel backwards by multiple steps
at once.
Like before, we model this with another transformation:
$\text{Rewind-Many}$.

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{Rewind-Many}(\mathcal{G}_b)$}\cr
&s_0 \gets \texttt{init}_b()\cr
&i \gets 0\cr
&\begin{aligned}
    &\underline{\mathcal{O}(x):}\cr
    &s_{i + 1}, y \gets \texttt{next}_b(s_i, x)\cr
    &\texttt{return } y\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Rewind}(j):}\cr
    &\texttt{assert } i >= j\cr
    &i \gets i - j\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{Rewind-Many}(\mathcal{G}_b)$}
\end{game}

The only difference with $\text{Rewind-1}$ is that now the adversary
can specify a hop distance $j$, and move backwards by $j$ steps,
rather than by just a single step.

A natural question arises: is being able to jump backwards multiple
steps at a time more powerful?

No.

\begin{claim}
    \label{claim:rewind-many-is-not-strong}
    $\text{Rewind-Many}$ is as strong as $\text{Rewind-1}$.
    In particular, for any abstract game $\mathcal{G}_b$, we have
    $\text{Rewind-Many}(\mathcal{G}_b) \leq \text{Rewind-1}(\mathcal{G}_b)$.
\end{claim}

The reduction works by emulating a large jump with many tiny jumps.

We define a wrapper $\Gamma$:

$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\Gamma$}\cr
&\begin{aligned}
    &\underline{\mathcal{O}(x):}\cr
    &\texttt{return } \texttt{super}.\mathcal{O}(x)\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Rewind}(j):}\cr
    &\texttt{assert } i >= j\cr
    &\texttt{super}.\texttt{Rewind}()\ j \text{ times }\cr
\end{aligned}\cr
\end{aligned}
}
$$

It then holds that:
$$
\text{Rewind-Many}(\mathcal{G}_b) = \Gamma \circ \text{Rewind-1}(\mathcal{G}_b)
$$

The only subtlety is that we need to guarantee that this emulation
is efficient, i.e. polynomial in $\lambda$.
Because the adversary for $\mathcal{A}$ against $\text{Rewind-Many}(\mathcal{G}_b)$
is efficient, we know that they make a number of queries to $\mathcal{O}$ polynomial
in $\lambda$.
This means that the largest $i$ they reach is also bounded, and thus so will the largest
$j$ they query.
This means that the number of iterations we do in the emulation is also bounded by a polynomial
in $\lambda$, so the reduction is efficient.

$\blacksquare$

\subsection{Forking Models}

So far, we've considered a simple model of time travel in which the
adversary observes a linear sequence of states, but they're allowed to
rewind time, undoing the most recent states.

\todo{figure?}

One shortcoming of this model is that the adversary has no ability to
return to previously seen states.
For example, after reaching a state $s$, an adversary can move backwards
in time, but then loses the ability to move back to the state $s$.

While they can travel backwards in time, they can't travel \emph{forwards}
at will.

In this section, we augment the adversary with the ability to travel both
forwards and backwards and time.
To do so, we consider a model in which the adversary is allowed
to \emph{fork} the timeline, and then travel between these parallel timelines.
Instead of having a linear sequence of states, we now have a tree:

\todo{figure?}

To model this technically, we introduce the notion of \emph{savepoints}.
By creating a savepoint at particular point in time, an adversary is
able to return to the state of the game at that point in time.
Each savepoint is thus a junction point in the tree.
By returning back to a savepoint, the adversary creates a new branch
at that junction:

\todo{figure}

\subsubsection{A Stack of Savepoints}

In the first model we consider, an adversary is free to create savepoints
anywhere, but can only jump to the most recently created savepoint.
We denote this capability by $\text{Fork-Stack}$:

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{Fork-Stack}(\mathcal{G}_b)$}\cr
&\begin{aligned}
    &s \gets \texttt{init}_b()\cr
    &\text{stack} \gets \varepsilon\cr
    &\underline{\mathcal{O}(x):}\cr
    &\ s, y \gets \texttt{next}_b(s, x)\cr
    &\ \texttt{return } y\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Fork}():}\cr
    &\ \text{stack}.\text{push}(s)\cr
    &\underline{\texttt{Load}():}\cr
    &\ \texttt{assert } \neg \text{stack}.\text{empty}\cr
    &\ s \gets \text{stack}.\text{pop}()\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{Fork-Stack}(\mathcal{G}_b)$}
\end{game}

We maintain a stack of savepoints, which are just snapshots of the state
of the game, but we can only reload the most recent savepoint, consuming
it.
The adversary also needs to proactively create savepoints if they want to be able
to rewind time.

How does $\text{Fork-Stack}$ compare with $\text{Rewind-Many}$?

It turns out that they're equivalent.

\begin{claim}
    \label{claim:fork-stack-is-not-stronger}
    For all abstract games $\mathcal{G}_b$, we have both
    $\text{Fork-Stack}(\mathcal{G}_b) \leq \text{Rewind-Many}(\mathcal{G}_b)$
    and $\text{Rewind-Many}(\mathcal{G}_b) \leq \text{Fork-Stack}(\mathcal{G}_b)$.
\end{claim}

\textbf{Proof Idea:}\\
Because we can only load the most recent savepoint, we can emulate
these loads using rewinding.

In the other direction, we need to emulate rewinding with forking.
One tricky aspect is that an adversary can rewind to any point without
having to create a savepoint there in advance.
In particular, they can choose how they rewind based on the results
of interacting with the game.
To accomodate this freedom, we can simply always make a savepoint,
allowing us to rewind by loading multiples times in a row.

\textbf{Proof:}\\
First, we show that $\text{Fork-Stack}(\mathcal{G}_b) \leq \text{Rewind-Many}(\mathcal{G}_b)$.

We define a wrapper $\Gamma$:

$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\Gamma$}\cr
&\begin{aligned}
    &i \gets 0\cr
    &\text{stack} \gets \varepsilon\cr
    &\cr
    &\underline{\mathcal{O}(x):}\cr
    &\ i \gets i + 1\cr
    &\ \texttt{return } \texttt{super}.\mathcal{O}(x)\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Fork}():}\cr
    &\ \text{stack}.\text{push}(i)\cr
    &\underline{\texttt{Load}():}\cr
    &\ \texttt{assert } \neg \text{stack}.\text{empty}\cr
    &\ \hat{i} \gets \text{stack}.\text{pop}()\cr
    &\ \texttt{super}.\texttt{Rewind}(i - \hat{i})\cr
    &\ i \gets \hat{i}\cr
\end{aligned}\cr
\end{aligned}
}
$$

This wrapper satisfies:
$$
\text{Fork-Stack}(\mathcal{G}_b) = \Gamma \circ \text{Rewind-Many}(\mathcal{G}_b)
$$
Basically, instead of keeping a stack of states, we can keep a stack of indices,
and the rewinding is enough to load previous states, because we can only ever load
the most recent state on the stack.

Next, we show that $\text{Rewind-Many}(\mathcal{G}_b) \leq \text{Rewind-Many}(\mathcal{G}_b)$.

In Claim \ref{claim:rewind-many-is-not-strong}, we showed that
$\text{Rewind-Many}(\mathcal{G}_b) \leq \text{Rewind-1}(\mathcal{G}_b)$, so
it suffices to prove that $\text{Rewind-1}(\mathcal{G}_b) \leq \text{Fork-Stack}(\mathcal{G}_b)$.

We define a wrapper $\Gamma$, which works by always creating a savepoint,
and then using those to implement rewinding.

$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\Gamma$}\cr
&\begin{aligned}
    &\underline{\mathcal{O}(x):}\cr
    &\ \texttt{super}.\texttt{Fork}()\cr
    &\ \texttt{return } \texttt{super}.\mathcal{O}(x)\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Rewind}():}\cr
    &\ \texttt{super}.\texttt{Load}()\cr
    &\cr
\end{aligned}\cr
\end{aligned}
}
$$

We have:
$$
\text{Rewind-1}(\mathcal{G}_b) = \Gamma \circ \text{Fork-Stack}(\mathcal{G}_b)
$$

One subtlety is that in $\texttt{Rewind}$, we don't perform any assertions,
whereas we'd usually check that $i > 0$.
This isn't necessary because $\texttt{super}.Load$ will check that the stack
isn't empty, which performs this duty.

$\blacksquare$

\subsubsection{Arbitrary Savepoints}

In the $\text{Fork-Stack}$ model, the adversary is limited to only
load the most recently created savepoint.
As we proved in Claim \ref{claim:fork-stack-is-not-stronger}, this model
gives no advantage over just being able to move backwards in time.

In order to capture the ability to move both backwards and forwards
at will, we can remove this restriction on which savepoints can be loaded.
We now maintain a list of savepoints, and these savepoints can loaded
in any order and multiple times, at will, without any restrictions.

More formally, we capture this notion with the
$\text{Fork}$ transformation:

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{Fork}(\mathcal{G}_b)$}\cr
&\begin{aligned}
    &s_0 \gets \texttt{init}_b()\cr
    &i, j \gets 0\cr
    &\underline{\mathcal{O}(x):}\cr
    &\ s_i, y \gets \texttt{next}_b(s_i, x)\cr
    &\ \texttt{return } y\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Fork}():}\cr
    &\ j \gets j + 1\cr
    &\ s_j \gets s_i\cr
    &\underline{\texttt{Load}(i'):}\cr
    &\ \texttt{assert } i' \leq j\cr
    &\ i \gets i'\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{Fork}(\mathcal{G}_b)$}
\end{game}

The essence is that the game now maintains multiple states $s_0, s_1, \ldots$
in parallel.
At any point, the adversary is free to switch which state is currently
being used, or to create a parallel state from the current one.
This captures the intuitive notion of traveling at will between
parallel timelines.

It turns out that this model of time travel is strictly stronger than the
others we've seen so far.

\begin{claim}
    \label{claim:fork-is-strong}
    $\text{Fork}$ is strictly stronger than $\text{Fork-Stack}$,
    assuming the existence of secure pseudo-random functions.

    In particular, given a secure PRF $F$, there exists a game $\mathcal{E}_b$ and adversary $\mathcal{A}$ such that 
    $\text{Rewind-1}(\mathcal{E}_b)$ is secure, yet $\epsilon(\mathcal{A} \circ \text{Fork}(\mathcal{E}_b)) = 1$.
\end{claim}

Consider the following game:

$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\mathcal{E}_b$}\cr
&\begin{aligned}
    &k \xleftarrow{R} \mathcal{K}\cr
    &x \gets \bot\cr
    &\text{queried} \gets 0\cr
    &\cr
    &\underline{\texttt{Win}(y):}\cr
    &\ \texttt{assert } x \neq \bot\cr
    &\ \texttt{assert } F(k, x) = y\cr
    &\ \texttt{return } b\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Query}(\hat{x}):}\cr
    &\ \texttt{assert } \text{queried} = 0\cr
    &\ \text{queried} \gets 1\cr
    &\ \texttt{return } F(k, \hat{x})\cr
    &\cr
    &\underline{\texttt{Input}():}\cr
    &\ \texttt{assert } \text{queried} = 0\cr
    &\ \text{queried} \gets 1\cr
    &\ x \xleftarrow{R} \mathcal{X}\cr
    &\ \texttt{return } x\cr
\end{aligned}\cr
\end{aligned}
}
$$

The idea is that we have a pseudo-random function, seeded with
a random key $k$.
The adversary can either query the function on an input of their choice,
or attempt to win the game, by receiving a challenge input $x$,
and then responding with the evaluation of the PRF $F$ on that input.
Crucially, they're allowed to perform a query, or to prepare
the challenge input, but not both.

This game is insecure against forking, as demonstrated by the following
strategy for $\text{Fork}(\mathcal{E}_b)$:

$$
\begin{aligned}
&x \gets \texttt{Input}()\cr
&\texttt{Fork}()\cr
&\texttt{Load}(0)\cr
&y \gets \texttt{Query}(x)\cr
&\texttt{Load}(1)\cr
&b \gets \texttt{Win}(y)\cr
&\texttt{return } b
\end{aligned}
$$

On the other hand, the game $\text{Rewind-1}(\mathcal{E}_b)$ remains
secure, provided that $|\mathcal{X}|^{-1}$ is negligeable in $\lambda$.
While the adversary can use rewinding to query multiple times,
they won't know which input $x$ they need to query.
Except with negligeable probability, each new call to $\texttt{Input}$
will yield a different value of $x$.
Because the adversary cannot predict the value of $x$, nor can they
learn the output of $F$ after they know $x$, since $F$ is a secure
PRF, they cannot win the game.

$\blacksquare$

\subsection{Summary}

To summarize our findings, we have the following hierarchy of models
of time travel:
$$
\text{No-Time-Travel} < \text{Rewind-1} = \text{Rewind-Many} = \text{Fork-Stack} < \text{Fork}
$$
So, even a bit of time travel helps, but then the next jump in capability
only comes with the ability to fork timelines and travel at will between them.
In other words, being able to jump backwards helps, and being able to jump
forwards too helps even more.

\section{On Depth and Position Restrictions}

In the models we've considered so far, there are limits on what time travel capabilities
the adversary has, but not in how they can use them.
The adversary can fork whenever they want, as many times as they want,
and advance each forked timeline at will.

In this section, we model these kinds of restriction on time travel,
and compare how they relate to each other.

\subsection{Modelling Restrictions}

The first kind of restriction is on the \emph{position} where an
adversary can fork.
Without time travel, the sequence of states $s_0, s_1, \ldots$
is indexed by $\mathbb{N}$.
A natural restriction is to only allow the adversary to
fork on a subset $P \subseteq \mathbb{N}$ of these states.
For example, the adversary may only be allowed to fork on the initial
state $s_0$, but not any other states.

The second kind of restriction is on the \emph{depth} of the forks.
In our model, the adversary is free to explore each fork to any depth.
They can advance the state in each fork arbitrarily.
With this restriction, we instead only allow the adversary to advance
the state in a forked timeline $d$ times.

More formally, given a set of positions $P \subseteq \mathbb{N}$, and
a depth
$ d \in \mathbb{N} \cup \{\infty\}$, we can define the following
transformation $\text{Fork}(P, d)$:

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{Fork}(P, d)(\mathcal{G}_b)$}\cr
&\begin{aligned}
    &s_0 \gets \texttt{init}_b()\cr
    &p_0 \gets 0\cr
    &\text{forkable} \gets \{0\}\cr
    &c_0 \gets \infty\cr
    &i, j \gets 0\cr
    &\underline{\mathcal{O}(x):}\cr
    &\ \texttt{assert } c_i > 0\cr
    &\ c_i \gets c_i - 1\cr
    &\ p_i \gets p_i + 1\cr
    &\ s_i, y \gets \texttt{next}_b(s_i, x)\cr
    &\ \texttt{return } y\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Fork}():}\cr
    &\ \texttt{assert } p_i \in P\cr
    &\ j \gets j + 1\cr
    &\ s_j, p_j, c_j \gets s_i, p_i, d\cr
    &\cr
    &\underline{\texttt{Load}(i'):}\cr
    &\ \texttt{assert } i' \leq j\cr
    &\ i \gets i'\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{Fork}(\mathcal{G}_b)$}
\end{game}

This game is like $\text{Fork}(\mathcal{G}_b)$, except with a few more restrictions.

First, we keep track of the position of each fork along the timeline,
via $p_i$. 
This allows us to prevent forks unless the position $p_i$ is contained
in the set of allowed positions $P$.

In order to restrict the depth of each fork, each fork is associated
with a counter $c_i$, which decrements each time the state advances.
The main timeline $c_0$, has the counter set to $\infty$, to allow
arbitrary progression.

\subsection{Comparing Restrictions}

$\text{Fork}(P, d)$ is actually equivalent to not having access
to time travel for certain parameters.
If $P = \emptyset$, or $d = 0$, then forking becomes
impossible.
This means that $\text{Fork}(\emptyset, d) = \text{Fork}(\emptyset, d')$,
and similarly for the other extreme values for $d$.

In fact, an equivalent condition is that $P$ contains no elements
in $\text{poly}(\lambda)$, i.e. bounded by a polynomial in the security
parameter $\lambda$.
For example, if $P = \{2^\lambda\}$, then the set isn't empty, but all
of the indices contained therein are unreachable, making time travel impossible.

At the other extreme, $\text{Fork}(\mathbb{N}, \infty) = \text{Fork}$.
If we can fork anywhere, and to any depth, we recover the general
model of forking defined previously.
In fact, it suffices that $d \notin \text{poly}(\lambda)$.
If the depth is larger than any polynomial in $\lambda$,
then it's impossible for the adversary to ever exhaust it, rendering
it effectively infinite.
For $P$, if for all $p \in \mathbb{N} / P$, we have $p \notin \text{poly}(\lambda)$,
then $P$ is effectively equivalent to $\mathbb{N}$, since the forbidden
positions aren't reachable by an efficient adversary.

It's clear that as $P$ and $d$ grow larger, the adversary grows
more powerful.
In particular, for all abstract games $\mathcal{G}_b$, and parameters
$P, P', d, d'$, we have:

\begin{itemize}
    \item If $P \subseteq P'$, then $\text{Fork}(P, d)(\mathcal{G}_b) \leq \text{Fork}(P', d)(\mathcal{G}_b)$.
    \item If $d \leq d'$, then $\text{Fork}(P, d)(\mathcal{G}_b) \leq \text{Fork}(P, d')(\mathcal{G}_b)$.
\end{itemize}

But, is it possible that certain parameter values are equivalent?
If we increase the size of the parameters, is that a strictly stronger
capability?

It is.
Increasing $P$ and $d$ yields a strictly stronger adversary.

\begin{claim}
    \label{claim:P-is-stronger}
    For all $d > 0$, if $P' / P \neq \emptyset$, then there exists a
    game $\mathcal{E}_b$ and adversary $\mathcal{A}$ such that 
    $\text{Fork}(P, d)(\mathcal{E}_b)$ is secure, yet $\epsilon(\mathcal{A} \circ \text{Fork}(P', d)(\mathcal{E}_b)) = 1$.
\end{claim}

The basic idea of the proof is that we engineer a game which requires
the adversary to fork at a position in $P'$, but not $P$, which demonstrates
the separation.

Given $p \in P' / P$, we can construct the following game:
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\mathcal{E}_b$}\cr
&k_0, k_1 \xleftarrow{R} \{0, 1\}^\lambda\cr
&i \gets -1\cr
&\begin{aligned}
    &\underline{\texttt{Query}(\sigma):}\cr
    &\ i \gets i + 1\cr
    &\ \texttt{if } i \neq p\cr
    &\ \quad \texttt{return } \bot\cr
    &\ \texttt{return } k_\sigma\cr
\end{aligned}
&\begin{aligned}
    &\ \underline{\texttt{Guess}(\hat{k}_0, \hat{k}_1):}\cr
    &\ \texttt{assert } \hat{k}_0 = k_0 \land \hat{k}_1 = k_1\cr
    &\ \texttt{return } b\cr
    &\cr
\end{aligned}\cr
\end{aligned}
}
$$
In order to win the game, the adversary needs to learn both $k_0$
and $k_1$.
Because of their size, this requires the adversary to make two
queries, both at step $p$.
This requires the adversary to be able to fork at step $p$,
which they are unable to do in $\text{Fork}(P, d)(\mathcal{E}_b)$.

$\blacksquare$

\begin{claim}
    \label{claim:P-is-stronger}
    For all $P$ with $\text{min}(P) \in \text{poly}(\lambda)$\footnote{This condition means that there exists an element in $P$ bounded by a polynomial in $\lambda$, so that $P$ isn't effectively empty.},
    if $d' > d$, and ${d' \in \text{poly}(\lambda)}$, then there exists a
    game $\mathcal{E}_b$ and adversary $\mathcal{A}$ such that 
    $\text{Fork}(P, d)(\mathcal{E}_b)$ is secure, yet ${\epsilon(\mathcal{A} \circ \text{Fork}(P, d')(\mathcal{E}_b)) = 1}$.
\end{claim}

The idea is to make a game which requires forking, and then advancing
the state a larger number of steps, which requires the ability to
reach a depth of $d'$.
We can do this by requiring the adversary to guess two keys $k_0$ and $k_1$.
In order to enforce a certain depth, we require the adversary to first
choose their index $\sigma$, and then wait a certain number of steps
before learning $k_\sigma$.

Given $p \in P$, we define the following game:
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\mathcal{E}_b$}\cr
&\begin{aligned}
    &k_0, k_1 \xleftarrow{R} \{0, 1\}^\lambda\cr
    &c \gets \infty\cr
    &\text{queried} \gets 0\cr
    &\underline{\texttt{Query}(\hat{\sigma}):}\cr
    &\ \texttt{assert } \text{queried} = 0\cr
    &\ \text{queried} \gets 1\cr
    &\ c \gets d' - 1\cr
    &\ \sigma \gets \hat{\sigma}
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Wait}():}\cr
    &\ c \gets c - 1\cr
    &\ \texttt{if } c = 0 \land \sigma \neq \bot\cr
    &\ \quad \texttt{return } k_\sigma\cr
    &\underline{\texttt{Guess}(\hat{k}_0, \hat{k}_1):}\cr
    &\ \texttt{assert } \hat{k}_0 = k_0 \land \hat{k}_1 = k_1\cr
    &\ \texttt{return } b\cr
    &\cr
\end{aligned}\cr
\end{aligned}
}
$$

In order to learn $k_\sigma$, the adversary first commits to their choice
of $\sigma$ in $\texttt{Query}$, and then they need to call $\texttt{Wait}$
$d' - 1$
times before learning the result.

A winning strategy against $\text{Fork}(P, d')$ would be:
$$
\begin{aligned}
&\texttt{Wait}()\ p \text{ times}\cr
&\texttt{Fork}()\cr
&\texttt{Query}(0)\cr
&k_0 \gets \texttt{Wait}()\ (d' - 1) \text{ times}\cr
&\texttt{Load}(0)\cr
&\texttt{Query}(1)\cr
&k_1 \gets \texttt{Wait}()\ (d' - 1) \text{ times}\cr
&b \gets \texttt{Guess}(k_0, k_1)\cr
&\texttt{return } b\cr
\end{aligned}
$$

Notably, this strategy requires a forking depth of at least $d'$,
in order to be able to make the queries to $\texttt{Wait}$,
and the final query to $\texttt{Guess}$.
One subtlety is that we need to wait at the start of the game in order
to advance the state $p$ times, at which point we're allowed to fork,
since $p \in P$.

On the other hand, since $d < d'$, $\text{Fork}(P, d)(\mathcal{E}_b)$
is secure.
The adversary cannot learn both $k_0$ and $k_1$ via $\texttt{Query}$
and $\texttt{Wait}$, since they lack the depth in their fork.
Since both keys have length $\lambda$, the adversary cannot guess
either of them with more than negligeable probability either.


$\blacksquare$

\section{Effects of Time Travel on Common Schemes}

In this section, we explore the impacts of time travel on various
crytographic schemes.

First, we look at some general results, namely that for \emph{stateless}
games, time travel provided no advantage.

Then, we look at more concrete results, showing that while $\text{IND-CCA}$
encryption is broken against time travel, $\text{IND-CPA}$ encryption
remain secure.
We also investigate signatures, showing that the $\text{EF-CMA}$
game is broken against time travel, but that a slightly weaker notion
of security remains secure.

\subsection{Stateless Schemes Remain Secure}

So far, we've shown that two models of time travel, $\text{Rewind-1}$
and $\text{Fork}$ provide strictly stronger capabilities.
The separation in both cases relied on the adversary being able to
``undo'' certain checks made inside of the game.

However, if the state of the game remains static after initialization,
then the adversary gains no advantage through time travel,
because the state never changes, so time travel has no effect on this
state.

More formally, given an abstract game $\mathcal{G}_b(\texttt{init}, \texttt{next})$,
we say that the game is \emph{stateless} if for all inputs and states $s$, $x$, it holds that:
$$
(s', \cdot) \gets \text{next}(s, x) \implies s' = s
$$
In other words, no matter what initial state we have, and what input
we pass to the game, the state will never change.

\begin{claim}
\label{claim:stateless-games}
For any stateless game $\mathcal{G}_b$, time travel provides no advantage.

In particular, we have $\text{Fork}(\mathcal{G}_b) \leq \mathcal{G}_b$.
\end{claim}

Since the state never changes, we can easily emulate the time
jumps by doing nothing.
More formally, if we write down the $\text{Fork}(\mathcal{G}_b)$
game explicitly, using the fact that the state doesn't change, we get
the game $\Gamma^0$:
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\Gamma^0$}\cr
&\begin{aligned}
    &s_0 \gets \texttt{init}_b()\cr
    &i, j \gets 0\cr
    &\underline{\mathcal{O}(x):}\cr
    &\ \cdot, y \gets \texttt{next}_b(s_0, x)\cr
    &\ \texttt{return } y\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Fork}():}\cr
    &\ j \gets j + 1\cr
    &\underline{\texttt{Load}(i'):}\cr
    &\ \texttt{assert } i' \leq j\cr
    &\ i \gets i'\cr
\end{aligned}\cr
\end{aligned}
}
$$

In $\Gamma^0$, the $\texttt{Fork}$ and $\texttt{Load}$ functions have
no impact on the rest of the game, allowing us to separate out
$\mathcal{G}_b$, to get:

$$
\Gamma^0 = 
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\Gamma^1$}\cr
&\begin{aligned}
    &i, j \gets 0\cr
    &\underline{\mathcal{O}(x):}\cr
    &\ \texttt{return } \texttt{super}.\mathcal{O}(x)\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Fork}():}\cr
    &\ j \gets j + 1\cr
    &\underline{\texttt{Load}(i'):}\cr
    &\ \texttt{assert } i' \leq j\cr
    &\ i \gets i'\cr
\end{aligned}\cr
\end{aligned}
} \circ \mathcal{G}_b
$$

which ends our reduction.

$\blacksquare$

The security of many schemes can be formulated with a stateless game,
so Claim \ref{claim:stateless-games} is a very useful tool
to quickly show security against time travel.
We make use of this tool frequently in the following sections.

\subsection{On Encryption}

One very common notion of security for encryption schemes is
that of $\text{IND-CCA}$ security \cite{ny90}.
In the $\text{IND}$ family of games, the adversary can present
the challenger with a message of their choice, receiving
back either the encryption of that message, or a random message.
\footnote{We use the ``real or random'' variant of $\text{IND}$, rather than the ``left or right'' variant, since the former is easier to use with state-separable proofs.}.
The difference between the variants $\text{IND}$, $\text{IND-CPA}$, and $\text{IND-CCA}$
lies in what additional oracles the adversary has access to.

In $\text{IND-CPA}$, the adversary has access to an oracle which lets them
receive encryptions of messages of their choice.
In $\text{IND-CCA}$, the adversary additionally has access to an oracle
allowing them to make decrypt ciphertexts of their choice.
Crucially, the adversary is \emph{not} allowed to decrypt any ciphertexts
produced by querying the challenge.

Both of these games are formally presented in the appendix, as
Game \ref{game:ind-cpa} and Game \ref{game:ind-cca}, respectively.

This difference is what allows time travel to break the
$\text{IND-CCA}$ game.
Because the game keeps track of which challenge ciphertexts have been produced,
disallowing decryption queries to those ciphertexts, the adversary
can use time travel to make the game ``forget'' which challenges have
been produced, and then use the decryption oracle to formally win.

\begin{claim}
\label{claim:ind-cca-broken}
Given any encryption scheme $\mathcal{E} = (\mathcal{K}, \mathcal{M}, \mathcal{C}, E, D)$, and message $m \in \mathcal{M}$, there exists a an adversary
$\mathcal{A}$, such that:
$$
\epsilon(\mathcal{A} \circ \text{Rewind-1}(\text{IND-CCA}_b(\mathcal{E}))) = 1 - |\mathcal{M}(|m|)|^{-1}
$$
where $|\mathcal{M}(|m|)|$ denotes the number of messages with the same length as $m$.
\end{claim}

The idea is quite simple: the adversary first obtains a challenge ciphertext (any message works),
and then makes the game forget that it produced this challenge, allowing the adversary
to then query the decryption oracle on the challenge, thus learning
information about the secret bit $b$.

More formally, consider the following strategy:
$$
\begin{aligned}
&c \gets \texttt{Challenge}(m)\cr
&\texttt{Rewind}()\cr
&\hat{m} \gets \texttt{Dec}(c)\cr
&\texttt{return } \hat{m} \neq m\cr
&
\end{aligned}
$$

The adversary will be allowed to query $\text{Dec}$ with $c$,
because the set of challenge ciphertexts is made empty by $\texttt{Rewind}$.
Then, if $b = 0$, the adversary will return $0$, since the ciphertext
will be an encryption of $m$.
Otherwise, if $b = 1$, the adversary will only return $0$ if the
random message happens to equal $m$, which happens with probability
$|\mathcal{M}(|m|)|^{-1}$.

$\blacksquare$

Crucially, our attack uses the fact that the $\text{IND-CCA}$ game
is stateful.
$\text{IND-CPA}$, on the other hand, remains secure, because
the game is inherently stateless.

\begin{claim}
\label{claim:ind-cpa-secure}
For any encryption scheme $\mathcal{E}$,
$\text{Fork}(\text{IND-CPA}(\mathcal{E})) \leq \text{IND-CPA}(\mathcal{E})$.
\end{claim}

Looking at the definition in Game \ref{game:ind-cpa}, it's clear
that the associated abstract game is $\emph{stateless}$.
We can thus apply Claim \ref{claim:stateless-games} to obtain our result.

$\blacksquare$

\subsection{On Signatures}

Next, we consider the security of signatures.
One common family of security games for signatures is that of
$*\text{UF-CMA}$ \cite{gmr88}.
In this family, the adversary has access to an oracles which can
sign messages, and they attempt to create a forged signature on a message.
The difference between the games lies in which messages the adversary
needs to forge a signature for.

In $\text{UUF-CMA}$, the game chooses a random message $m$, and the adversary
must forge a signature for $m$.
Naturally, the adversary is not allowed to use the signing oracle on
$m$.

In $\text{EUF-CMA}$, the adversary can forge a signature for any message
of their choice, so long as they didn't use that message
with the signing oracle.

Both of these games are formally presented in the appendix,
as Game \ref{game:uuf-cma} and Game \ref{game:euf-cma}, respectively.

In $\text{EUF-CMA}$, the game needs to keep track of which messages
it has signed for the adversary.
This book-keeping is what allows the game to be broken by time-travel.
An adversary can sign a message of their choice, and then rewind time
to make the game forget that it ever signed that message.

\begin{claim}
\label{claim:euf-cma}
Given any signature scheme
$\mathcal{S} = (\mathcal{PK}, \mathcal{SK}, \mathcal{M}, \mathcal{C}, \Sigma, \text{Gen}, \text{Sign}, \text{Verify})$, and message $m \in \mathcal{M}$,
there exists an adversary $\mathcal{A}$ such that:
$$
\epsilon(\mathcal{A} \circ \text{Rewind-1}(\text{EUF-CMA}_b(\mathcal{S}))) = 1
$$
\end{claim}
The idea is that the adversary can obtain a signature for $m$
via the oracle $\texttt{Sign}$, and then rewind time to make the game
forget that it signed this message, allowing it to query $\texttt{Win}$.

More formally, the following strategy always succeeds:
$$
\begin{aligned}
&\sigma \gets \texttt{Sign}(m)\cr
&\texttt{Rewind}()\cr
&\texttt{return } \texttt{Win}(m, \sigma)\cr
\end{aligned}
$$

By the correctness property for signatures, the $\sigma$ returned
by $\texttt{Sign}$ will successfully verify.
Additionally, after $\texttt{Rewind}()$, the set $\text{signed}$
will be empty, allowing the adversary to successfully query $\texttt{Win}$.

$\blacksquare$

On the other hand, $\text{UUF-CMA}$ remains secure.
This is because the message $m$ that the adversary needs to sign
is fixed after initializing the game, which means that time travel
doesn't help, because no state is modified in the game.


\begin{claim}
\label{claim:uuf-cpa-secure}
For any signature scheme $\mathcal{S}$,
$\text{Fork}(\text{UUF-CMA}(\mathcal{S})) \leq \text{UUF-CMA}(\mathcal{S})$.
\end{claim}

Looking at the definition in Game \ref{game:uuf-cma}, it's clear
that the associated abstract game is $\emph{stateless}$.
We can thus apply Claim \ref{claim:stateless-games} to obtain our result.

$\blacksquare$

\section{Further Work}

In this section, we look at some unanswered questions and possible
lines of improvement for this work.

While we've considered a handful of different models for time travel,
along with restrictions for these models, we expect that further work
might develop more powerful models, or more fine-grained restrictions.

Another interesting line of work would be to investigate which classes
of game make certain models of time-travel equivalent.
Similar to Claim \ref{claim:stateless-games} for stateless games,
it might be possible that certain classes of games make
$\text{Fork}$ and $\text{Fork-Stack}$ equivalent, for example.

In Claim \ref{claim:fork-is-strong}, we separated $\text{Fork}$
from $\text{Fork-Stack}$, assuming the existence of secure
pseudo-random functions.
One natural extension of this work would be to find the weakest
primitive necessary to separate the two transformations, or
even prove that a separation exists without any cryptographic assumptions.

In this work, we've considered standalone security, using games.
Further work might extend models of travel to work with
simulation based security, or even universally composable security \cite{can01}.
Unfortunately, we expect that modelling time travel in a concurrent setting will prove
substantially more difficult than modelling it in the standalone setting.
On the other hand, this model would more likely match realistic deployments
of time machines.


\section{Conclusion}

\bibliographystyle{alpha}
{\small \bibliography{bib}}
\clearpage
\appendix

\section{Additional Game Definitions}

\subsection{Encryption}

An encryption scheme $\mathcal{E}$ consists of types $\mathcal{K}, \mathcal{M}, \mathcal{C}$,
along with functions $E : \mathcal{K} \times \mathcal{M} \xleftarrow{R} \mathcal{C}$ and $D : \mathcal{K} \times \mathcal{C} \to \mathcal{M}$.
By $\mathcal{M}(|m|)$ we denote the distribution of messages with the same
length as $m$.

The encryption scheme must satisfy a correctness property:
$$
\forall k \in \mathcal{K},\ m \in \mathcal{M}.\ P[D(E(k, m)) = m] = 1
$$
Encrypting and then decrypting a message should return that same message.

The security of an encryption scheme can be captured by one of the following
two games:

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{IND-CPA}_b$}\cr
&k \xleftarrow{R} \mathcal{K}\cr
&\begin{aligned}
    &\underline{\texttt{Challenge}(m):}\cr
    &\ m_1 \xleftarrow{R} \mathcal{M}(|m_0|)\cr
    &\ c \gets E(k, m_b)\cr
    &\ \texttt{return } c\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Enc}(m):}\cr
    &\ \texttt{return } E(k, m)\cr
    &\cr
    &\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{IND-CPA}_b$}
\label{game:ind-cpa}
\end{game}
\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{IND-CCA}_b$}\cr
&k \xleftarrow{R} \mathcal{K}\cr
&S \gets \emptyset\cr
&\begin{aligned}
    &\underline{\texttt{Challenge}(m_0):}\cr
    &\ m_1 \xleftarrow{R} \mathcal{M}(|m_0|)\cr
    &\ c \gets E(k, m_b)\cr
    &\ S \gets S \cup \{c\}\cr
    &\ \texttt{return } c\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Enc}(m):}\cr
    &\ \texttt{return } E(k, m)\cr
    &\underline{\texttt{Dec}(c):}\cr
    &\ \texttt{assert } c \notin S\cr
    &\ \texttt{return } D(k, c)\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{IND-CCA}_b$}
\label{game:ind-cca}
\end{game}

\subsection{Signatures}
A signature scheme $\mathcal{S}$ consists of types $\mathcal{PK}, \mathcal{SK}, \mathcal{M}, \mathcal{C}, \Sigma$,
along with functions:
$$
\begin{aligned}
&\text{Gen} : () \xrightarrow{R} \mathcal{SK} \times \mathcal{PK}\cr
&\text{Sign} : \mathcal{SK} \times \mathcal{M} \xrightarrow{R} \Sigma\cr
&\text{Verify} : \mathcal{PK} \times \mathcal{M} \times \Sigma \to \{0, 1\}\cr
\end{aligned}
$$

For correctness, we require that all signatures produced with a given
key will successfully verify.
More formally, for any message $m$, the following procedure always succeeds:
$$
\begin{aligned}
&(\text{sk}, \text{pk}) \xleftarrow{R} \text{Gen}()\cr
&\sigma \gets \text{Sign}(\text{sk}, m)\cr
&\texttt{return } \text{Verify}(\text{pk}, m, \sigma)\cr
\end{aligned}
$$

We consider two notions of security for signature schemes:
$\text{UUF-CMA}$ and $\text{EUF-CMA}$, with the former being weaker.

\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{UUF-CMA}_b$}\cr
&\begin{aligned}
    &(\text{sk}, \text{pk}) \xleftarrow{R} \text{Gen}()\cr
    &m \xleftarrow{R} \mathcal{M}\cr
    &\underline{\texttt{Win}(\sigma):}\cr
    &\ \texttt{assert } \text{Verify}(\text{pk}, m, \sigma)\cr
    &\ \texttt{return } b\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Challenge}()}\cr
    &\ \texttt{return } m\cr
    &\underline{\texttt{Sign}(\hat{m}):}\cr
    &\ \texttt{assert } \hat{m} \neq m\cr
    &\ \texttt{return } \text{Sign}(\text{sk}, \hat{m})\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{UUF-CMA}_b$}
\label{game:uuf-cma}
\end{game}
\begin{game}
\captionsetup{justification=centering}
$$
\boxed{
\begin{aligned}
&\colorbox{pink}{\large $\text{EUF-CMA}_b$}\cr
&(\text{sk}, \text{pk}) \xleftarrow{R} \text{Gen}()\cr
&\text{signed} \gets \emptyset\cr
&\begin{aligned}
    &\underline{\texttt{Win}(m, \sigma):}\cr
    &\ \texttt{assert } m \notin \text{signed}\cr
    &\ \texttt{assert } \text{Verify}(\text{pk}, m, \sigma)\cr
    &\ \texttt{return } b\cr
\end{aligned}
&\begin{aligned}
    &\underline{\texttt{Sign}(m):}\cr
    &\ \text{signed} \gets \text{signed} \cup \{m\}\cr
    &\ \texttt{return } \text{Sign}(\text{sk}, m)\cr
\end{aligned}\cr
\end{aligned}
}
$$
\caption{$\text{EUF-CMA}_b$}
\label{game:euf-cma}
\end{game}

\end{document}